import streamlit as st
from duckduckgo_search import DDGS
from openai import OpenAI
import trafilatura
import requests
import concurrent.futures
import sys
import time

# --- 1. æ–‡å­—ã‚³ãƒ¼ãƒ‰è¨­å®š ---
if sys.stdout.encoding != 'utf-8':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass

# --- 2. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="My Perplexity V2", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– My Perplexity V2 (Chat & Switch)")

# --- 3. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– (å±¥æ­´ä¿æŒç”¨) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # APIã‚­ãƒ¼ç®¡ç† (Secretså¯¾å¿œ - ã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆ)
    api_key = ""
    try:
        # st.secrets ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ try-except ã§å›²ã‚€
        if "OPENAI_API_KEY" in st.secrets:
            api_key = st.secrets["OPENAI_API_KEY"]
    except FileNotFoundError:
        pass # ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ç„¡è¦–
    except Exception:
        pass # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚‚ç„¡è¦–

    # Secretsã‹ã‚‰å–ã‚Œãªã‹ã£ãŸå ´åˆã®ã¿å…¥åŠ›æ¬„ã‚’è¡¨ç¤º
    if not api_key:
        api_key = st.text_input("OpenAI API Key", type="password")

    st.markdown("---")
    
    # â˜… ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿ã‚¹ã‚¤ãƒƒãƒ â˜…
    mode = st.radio(
        "å‹•ä½œãƒ¢ãƒ¼ãƒ‰",
        ["ğŸš€ çˆ†é€Ÿ (å˜ç™º)", "ğŸ’¬ ä¼šè©± (æ–‡è„ˆ)"],
        index=0,
        help="ã€çˆ†é€Ÿã€‘å±¥æ­´ã‚’ç„¡è¦–ã—ã¦æœ€é€Ÿã§æ¤œç´¢ã—ã¾ã™ã€‚\nã€ä¼šè©±ã€‘ã€Œãã‚Œã¯é«˜ã„ï¼Ÿã€ãªã©æ–‡è„ˆã‚’è¸ã¾ãˆã¦æ¤œç´¢ã—ã¾ã™ã€‚"
    )
    
    model_name = "gpt-5-nano-2025-08-07" # ã¾ãŸã¯ gpt-4o-mini
    target_count = st.slider("æ¤œç´¢ä»¶æ•°", 5, 20, 8)
    
    # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
}

# --- 5. ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤ ---

def generate_search_keywords(query, client, mode, history):
    """
    æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    ã€ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã€‘ã®å ´åˆã¯ã€å±¥æ­´(history)ã‚’åŠ å‘³ã—ã¦æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’è€ƒãˆã‚‹ã€‚
    """
    if mode == "ğŸš€ çˆ†é€Ÿ (å˜ç™º)":
        # Pythonã®ã¿ã§çˆ†é€Ÿç”Ÿæˆ
        keywords = [query]
        keywords.append(f"{query} ã¨ã¯")
        keywords.append(f"{query} news")
        return list(dict.fromkeys(keywords))[:3]
    
    else:
        # ä¼šè©±ãƒ¢ãƒ¼ãƒ‰: æ–‡è„ˆã‚’ç†è§£ã—ã¦æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’ä½œã‚‹ (ã“ã“ãŒå°‘ã—é‡ããªã‚‹è¦å› )
        # ç›´è¿‘3ãƒ©ãƒªãƒ¼åˆ†ãã‚‰ã„ã®å±¥æ­´ã‚’æ¸¡ã™
        recent_history = history[-6:] 
        
        prompt = f"""
        ã“ã‚Œã¾ã§ã®ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°ã®è³ªå•ã€Œ{query}ã€ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ã€ä¼šè©±å±¥æ­´ã€‘
        {recent_history}
        
        å‡ºåŠ›ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’æ”¹è¡ŒåŒºåˆ‡ã‚Šã§ã€‚
        ä¾‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œãã‚Œã¯ã„ãã‚‰ï¼Ÿã€ã¨èã„ãŸã‚‰ -> "iPhone 16 pro ä¾¡æ ¼" ã®ã‚ˆã†ã«å…·ä½“åŒ–ã™ã‚‹ã“ã¨ã€‚
        """
        
        try:
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content.strip().split("\n")
        except:
            return [query]

def fetch_worker(url, title, snippet):
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å–å¾— (2ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ)"""
    data = {'title': title, 'url': url, 'content': "", 'type': "waiting"}
    try:
        response = requests.get(url, headers=HEADERS, timeout=2.0)
        if response.status_code == 200:
            if response.encoding is None or response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding
            content = trafilatura.extract(response.text, include_comments=False)
            if content and len(content) > 200:
                data['content'] = content[:1000]
                data['type'] = "full"
                return data
    except:
        pass
    
    # å¤±æ•—æ™‚ã¯ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
    if snippet and len(snippet) > 30:
        data['content'] = snippet
        data['type'] = "snippet"
        return data
    return None

# --- 6. ãƒ¡ã‚¤ãƒ³ãƒãƒ£ãƒƒãƒˆå‡¦ç† ---

# 1. éå»ã®ä¼šè©±ã‚’è¡¨ç¤º
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        # å‚ç…§ã‚½ãƒ¼ã‚¹ãŒã‚ã‚Œã°è¡¨ç¤º
        if "sources" in msg:
            with st.expander("ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹"):
                for src in msg["sources"]:
                    st.markdown(f"- [{src['title']}]({src['url']})")

# 2. ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
if query := st.chat_input("ä½•ã«ã¤ã„ã¦èª¿ã¹ã¾ã™ã‹ï¼Ÿ"):
    
    # APIã‚­ãƒ¼ãŒç©ºãªã‚‰ã‚¹ãƒˆãƒƒãƒ—
    if not api_key:
        st.error("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()
        
    client = OpenAI(api_key=api_key)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤ºï¼†ä¿å­˜
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)

    # AIã®å›ç­”å‡¦ç†
    with st.chat_message("assistant"):
        
        # --- A. æ¤œç´¢æˆ¦ç•¥ãƒ•ã‚§ãƒ¼ã‚º ---
        status_container = st.status("ğŸš€ ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹...", expanded=True)
        
        with status_container:
            st.write("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆä¸­...")
            
            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆ
            keywords = generate_search_keywords(
                query, 
                client, 
                mode, 
                st.session_state.messages[:-1] # ä»Šå›ã®è³ªå•ã‚’é™¤ãå±¥æ­´
            )
            st.caption(f"Keywords: {keywords}")
            
            st.write("Webã‚’æ¤œç´¢ä¸­...")
            candidates = []
            seen_urls = set()
            
            with DDGS() as ddgs:
                for q in keywords:
                    try:
                        region = 'wt-wt' if 'news' in q else 'jp-jp'
                        results = list(ddgs.text(q, region=region, max_results=5))
                        for res in results:
                            if res['href'] not in seen_urls and not res['href'].endswith('.pdf'):
                                seen_urls.add(res['href'])
                                candidates.append(res)
                    except:
                        pass
            
            # å€™è£œã‚’çµã‚‹
            candidates = candidates[:target_count * 2]
            st.write(f"ğŸ” {len(candidates)}ä»¶ã®ã‚½ãƒ¼ã‚¹ã¸ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")
            
            # --- B. ä¸¦åˆ—å–å¾—ãƒ•ã‚§ãƒ¼ã‚º ---
            valid_results = []
            progress_bar = st.progress(0)
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
                futures = [executor.submit(fetch_worker, res['href'], res['title'], res['body']) for res in candidates]
                
                for future in concurrent.futures.as_completed(futures):
                    result = future.result()
                    if result:
                        valid_results.append(result)
                        progress_bar.progress(min(len(valid_results) / target_count, 1.0))
                        
                        if len(valid_results) >= target_count:
                            executor.shutdown(wait=False, cancel_futures=True)
                            break
            
            status_container.update(label=f"å®Œäº†ï¼ {len(valid_results)}ä»¶ã®æƒ…å ±ã‚’ç¢ºä¿ã€‚", state="complete", expanded=False)

        # --- C. å›ç­”ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º ---
        if valid_results:
            # 1. ã‚½ãƒ¼ã‚¹ã®å…ˆè¡Œè¡¨ç¤º (Level 25ã®UX)
            st.markdown("### ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹")
            cols = st.columns(4)
            for i, res in enumerate(valid_results):
                with cols[i % 4]:
                    icon = "âš¡" if res['type'] == "full" else "ğŸ“"
                    short_title = res['title'][:15] + "..."
                    st.info(f"**[{i+1}] {short_title}**\n\n[{icon} Link]({res['url']})")
            
            st.divider()

            # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä½œæˆ
            context_text = ""
            for i, res in enumerate(valid_results):
                context_text += f"[{i+1}] {res['title']}\n{res['content']}\n\n"

            # 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ (å±¥æ­´ã‚’å…¥ã‚Œã‚‹ã‹ã©ã†ã‹ã®åˆ†å²)
            if mode == "ğŸš€ çˆ†é€Ÿ (å˜ç™º)":
                system_prompt = "ã‚ãªãŸã¯é«˜é€Ÿæ¤œç´¢AIã§ã™ã€‚æ¤œç´¢çµæœã®ã¿ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                user_content = f"è³ªå•: {query}\n\nã€æ¤œç´¢çµæœã€‘\n{context_text}\n\nçµè«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã§è©³ã—ãç­”ãˆã¦ã€‚"
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ]
            else:
                # ä¼šè©±ãƒ¢ãƒ¼ãƒ‰: éå»ã®ã‚„ã‚Šå–ã‚Šã‚‚å«ã‚ã¦æŠ•ã’ã‚‹
                system_prompt = "ã‚ãªãŸã¯å„ªç§€ãªãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚éå»ã®ä¼šè©±ã¨æœ€æ–°ã®æ¤œç´¢çµæœã‚’çµ±åˆã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
                messages = [{"role": "system", "content": system_prompt}]
                
                # éå»ãƒ­ã‚°ã‚’å°‘ã—è¿½åŠ  (ãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ã®ãŸã‚ç›´è¿‘3ã¤ãã‚‰ã„)
                for m in st.session_state.messages[-4:-1]:
                    messages.append({"role": m["role"], "content": m["content"]})
                
                user_content = f"æœ€æ–°ã®è³ªå•: {query}\n\nã€æœ€æ–°ã®æ¤œç´¢çµæœã€‘\n{context_text}\n\næ–‡è„ˆã‚’è¸ã¾ãˆã¦è©³ã—ãç­”ãˆã¦ã€‚"
                messages.append({"role": "user", "content": user_content})

            # 4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å›ç­”
            response_container = st.empty()
            full_response = ""
            
            try:
                stream = client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    stream=True
                )
                
                for chunk in stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        full_response += content
                        response_container.markdown(full_response + "â–Œ")
                
                response_container.markdown(full_response)
                
                # 5. å±¥æ­´ã«ä¿å­˜ (ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚‚ä¸€ç·’ã«ä¿å­˜ã—ã¦ãŠãã¨å¾Œã§è¦‹è¿”ã›ã‚‹)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "sources": valid_results
                })
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                
        else:
            st.error("æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")